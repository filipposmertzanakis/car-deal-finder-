name: Car Scraping with Undetected Chromedriver

on:
  schedule:
    - cron: '*/30 * * * *'  # Every 30 minutes
  workflow_dispatch:          # Allow manual triggers

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 30       # Prevent hanging jobs

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Verify script exists
      run: |
        if [ ! -f "new_workflow/scrape_with_score.py" ]; then
          echo "❌ Error: Script not found!"
          exit 1
        fi
        echo "✅ Script found"

    - name: Set up Python 3.11
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'

    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y \
          wget \
          unzip \
          libnss3-dev \
          libgbm-dev \
          libxss1 \
          libappindicator3-1 \
          fonts-liberation \
          libnspr4 \
          libnss3 \
          libx11-xcb1 \
          libxtst6 \
          libxrandr2 \
          libasound2-dev \
          libpangocairo-1.0-0 \
          libatk1.0-0 \
          libcairo-gobject2 \
          libgtk-3-0 \
          libgdk-pixbuf2.0-0

    - name: Setup Chrome and Chromedriver
      run: |
        echo "⬇️ Downloading and installing Chrome..."
        
        # Download stable Chrome version
        wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | sudo apt-key add -
        echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" | sudo tee /etc/apt/sources.list.d/google-chrome.list
        sudo apt-get update
        sudo apt-get install -y google-chrome-stable
        
        # Get Chrome version and download matching chromedriver
        CHROME_VERSION=$(google-chrome --version | grep -oE '[0-9]+\.[0-9]+\.[0-9]+')
        CHROME_MAJOR_VERSION=$(echo $CHROME_VERSION | cut -d. -f1)
        echo "Chrome version: $CHROME_VERSION (Major: $CHROME_MAJOR_VERSION)"
        
        # Download matching chromedriver
        echo "⬇️ Downloading matching Chromedriver..."
        CHROMEDRIVER_URL="https://storage.googleapis.com/chrome-for-testing-public/${CHROME_VERSION}/linux64/chromedriver-linux64.zip"
        
        # If specific version not found, try latest stable
        if ! wget -q --spider "$CHROMEDRIVER_URL"; then
          echo "Specific version not found, trying latest stable..."
          LATEST_VERSION=$(curl -s "https://googlechromelabs.github.io/chrome-for-testing/latest-versions-per-milestone.json" | grep -o "\"$CHROME_MAJOR_VERSION\":{\"version\":\"[^\"]*" | cut -d'"' -f4)
          CHROMEDRIVER_URL="https://storage.googleapis.com/chrome-for-testing-public/${LATEST_VERSION}/linux64/chromedriver-linux64.zip"
        fi
        
        wget -O chromedriver.zip "$CHROMEDRIVER_URL"
        unzip chromedriver.zip
        sudo mv chromedriver-linux64/chromedriver /usr/local/bin/
        sudo chmod +x /usr/local/bin/chromedriver
        
        # Create symlinks for compatibility
        sudo ln -sf /usr/bin/google-chrome /usr/local/bin/google-chrome
        
        echo "✅ Installed versions:"
        google-chrome --version
        chromedriver --version
        
        # Test Chrome can start
        echo "🧪 Testing Chrome startup..."
        timeout 10s google-chrome --headless --no-sandbox --disable-gpu --dump-dom https://www.google.com > /dev/null || echo "Chrome test completed"

    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install undetected-chromedriver requests beautifulsoup4 selenium supabase python-dotenv

    - name: Run scraping script
      env:
        SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
        SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
        EMAIL_HOST: ${{ secrets.EMAIL_HOST }}
        EMAIL_PORT: ${{ secrets.EMAIL_PORT }}
        EMAIL_USER: ${{ secrets.EMAIL_USER }}
        EMAIL_PASSWORD: ${{ secrets.EMAIL_PASSWORD }}
      run: |
        # Enable debug logging
        export DEBUG=1
        python -u new_workflow/scrape_with_score.py 2>&1 | tee scrape.log
        echo "=== Scrape log ==="
        cat scrape.log
        echo "=================="

    - name: Upload logs on failure
      if: failure()
      uses: actions/upload-artifact@v4
      with:
        name: scrape-logs
        path: scrape.log